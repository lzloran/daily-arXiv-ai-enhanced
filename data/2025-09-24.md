<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 60]
- [cs.AI](#cs.AI) [Total: 48]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种统一的多任务学习框架，通过动态提示调度机制解决大语言模型在多任务和跨域设置下的泛化限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法如SPoT依赖固定提示模板，存在泛化能力不足的问题。本研究旨在通过动态提示调度来增强模型对不同任务语义差异的捕捉能力。

Method: 采用提示池和任务感知调度策略，动态组合和对齐不同任务的提示。通过任务嵌入和门控机制精细控制提示信号，构建灵活的任务间共享路径，并采用联合多任务学习优化目标。

Result: 实验证明该方法在语言理解和知识推理任务上显著提升性能，有效维持模型稳定性并增强可迁移性。

Conclusion: 所提出的提示调度机制在统一多任务建模和跨域适应方面具有显著的应用价值和有效性。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [2] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估LLMs数学能力的基准测试，涵盖12个核心技能维度，分为知识理解、问题解决与沟通、元技能与创造力三个领域，通过分类问题和设计任务来构建模型数学能力的全面、细粒度、可解释的配置文件。


<details>
  <summary>Details</summary>
Motivation: 现有数学基准测试主要关注最终答案的正确性，缺乏对模型底层数学技能的细粒度评估。GAUSS旨在通过技能维度分类来更全面地评估LLMs的数学智能。

Method: 将数学问题按认知技能分类，设计能隔离特定能力的任务，构建12个技能维度的评估框架，分为三个主要领域。

Result: 通过GAUSS基准测试GPT-5-thinking，揭示了其数学能力的优势、弱点以及与o4-mini-high的差异，证明了多维技能评估的价值。

Conclusion: GAUSS基准测试能够提供更全面、细粒度和可解释的模型数学能力评估，有助于更好地理解LLMs的数学智能。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [3] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出了一种基于Rubin因果模型的事件因果关系识别方法，通过将第一个事件视为治疗、第二个事件视为结果，并利用合成控制方法生成虚拟双胞胎来估计因果效应。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果关系识别方法主要依赖语言模式和多跳关系推理，容易因因果关系的非正式使用和虚假图形推理而导致错误识别。需要更稳健的方法来区分因果关系和相关关系。

Method: 采用Rubin因果模型框架，将事件对视为治疗-结果关系。使用合成控制方法从相关历史数据中生成虚拟双胞胎，通过文本嵌入合成和反演技术来估计治疗干预对结果可能性的影响。

Result: 该方法在因果关系基准测试COPES-hard上表现出色，识别效果优于包括GPT-4在内的先前方法，能够更稳健地识别事件间的因果关系。

Conclusion: 基于因果推断框架的事件因果关系识别方法能够有效克服传统方法的局限性，通过概念性干预和合成控制技术提供了更可靠的因果关系识别方案。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [4] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一种自动提示优化框架，通过联合优化系统提示和用户提示，使用结构化评分标准和快速迭代，实现高效提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示优化方法通常只关注用户提示，依赖非结构化反馈，需要大量样本和长迭代周期，导致成本高且脆弱。

Method: ZERA使用八个可泛化标准对提示进行评分，并基于结构化批评修订提示，通过最小样本和短迭代周期实现快速收敛。

Result: 在五个LLM和九个数据集上的实验表明，ZERA在推理、摘要和代码生成任务上均优于强基线。

Conclusion: ZERA通过联合优化系统提示和用户提示，实现了更有效的提示构建，各组件对性能提升均有贡献。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [5] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 论文研究了外部信息对具有逐步推理能力的大语言模型的影响，发现思考模式是双刃剑：有帮助的信息能提高准确性，但误导性信息会导致性能灾难性下降，且思考过程会放大错误。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，LLMs经常需要处理外部信息，这些信息可能有用、无关甚至误导。研究旨在系统测试模型对这些不同类型信息的鲁棒性。

Method: 引入SciAux数据集（基于ScienceQA），系统测试模型对有帮助、无关和误导性信息的鲁棒性，分析思考过程对信息处理的影响。

Result: 发现模型的有意识思考模式是双刃剑：有帮助的上下文提高准确性，但误导信息导致性能灾难性下降，且思考过程会放大错误而非增强鲁棒性。

Conclusion: 关键挑战不仅是让模型"思考"，更要赋予它们评估推理所依赖信息的关键能力，思考过程需要具备批判性评估信息的能力。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [6] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 提出了一种过程监督的多智能体框架来优化检索增强生成（RAG）中检索器和生成器之间的协调问题，通过决策制定器和知识选择器两个轻量级智能体，结合过程级奖励和树状结构探索策略，在问答任务上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统中，检索器和生成器独立开发导致交互不理想：检索器可能返回不相关或冗余文档，生成器未能充分利用检索到的证据。需要解决两者之间的协调问题。

Method: 采用过程监督的多智能体框架，包含决策制定器（决定何时继续检索或停止生成答案）和知识选择器（筛选最有用的证据文档）。使用LLM作为评判员提供过程级奖励，采用树状结构探索策略，使用PPO进行端到端训练。

Result: 在单跳和多跳问答基准测试中，该方法相比标准RAG基线实现了更高的准确率、更稳定的收敛性，并产生了更可解释的推理轨迹。

Conclusion: 该框架是模块化且即插即用的，无需修改检索器或生成器，适用于实际RAG应用，有效提升了检索增强生成系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [7] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 提出了一种新颖的对话情感识别与预测架构ERFC，用于预测未来话语的情感，在呼叫中心等场景中具有重要应用价值。


<details>
  <summary>Details</summary>
Motivation: 在呼叫中心等对话场景中，客服人员需要及时了解客户情绪变化并提供适当解决方案。预测未来话语的情感可以帮助客服人员更好地管理客户体验，将不满客户转化为满意客户。

Method: 提出ERFC架构，综合考虑多模态、情感的不同属性、上下文以及对话中说话者话语之间的相互依赖关系。

Result: 在IEMOCAP数据集上的密集实验证明了所提出ERFC方法的可行性。

Conclusion: 该方法在呼叫中心等客户满意度至关重要的应用场景中具有巨大的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [8] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 本文评估了8个开源LLM检测反犹内容的能力，提出了Guided-CoT提示技术，显著提升了模型性能，并分析了LLM在效用、可解释性和可靠性方面的差异。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是重要但具有挑战性的任务，需要持续训练以适应社交媒体的变化。本研究旨在评估开源LLM在检测反犹内容方面的能力。

Method: 利用上下文定义作为政策指南，探索多种提示技术，设计了新的类似思维链的提示方法Guided-CoT，并引入指标量化模型生成理由的语义差异。

Result: Guided-CoT有效处理上下文政策，在所有评估模型中提高了性能，不受解码配置、模型大小或推理能力影响。Llama 3.1 70B表现优于微调的GPT-3.5。

Conclusion: 实验揭示了LLM在效用、可解释性和可靠性方面的显著差异，以及模型生成理由中的语义分歧和矛盾行为。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [9] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 本文提出TEMPO算法，通过前缀树结构解决LLM推理中的token级信用分配问题，在数学和医疗QA任务上优于PPO和GRPO。


<details>
  <summary>Details</summary>
Motivation: 强化学习能提升LLM推理能力，但长序列中的稀疏延迟奖励使得token级信用分配成为关键瓶颈。在可验证奖励设置下（如数学和医疗QA），只有少数决策token对结果有重要影响。

Method: 提出Prefix-to-Tree（P2T）方法将响应组转换为前缀树，计算非参数前缀值。基于P2T开发TEMPO算法，结合GRPO的组相对结果信号和分支门控的时序差分修正，无需学习价值网络。

Result: 在Qwen3-1.7B/4B模型上，TEMPO在分布内（MATH、MedQA）和分布外（GSM-HARD、AMC23等）基准测试中均优于PPO和GRPO，验证准确率更高且训练时间相近。

Conclusion: TEMPO提供了一种简单有效的token级信用分配方法，在可验证奖励设置下显著提升LLM推理性能，无需复杂价值网络训练。

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [10] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该论文探索了一种新范式：将LLM作为知识图谱推理路径的奖励模型，让模型学习判断候选路径是否能正确诊断患者输入。实验发现特定奖励优化和蒸馏能带来强路径判断性能，但向下游任务的迁移性较弱。


<details>
  <summary>Details</summary>
Motivation: LLMs在诊断推理中缺乏可靠的知识基础推理能力，而知识图谱提供了结构化生物医学知识。传统方法通过检索增强生成或微调将KG内容插入提示，而非实现结构化推理。

Method: 将LLM作为KG推理路径的奖励模型，评估五种任务制定和八种训练范式。测试路径判断能力是否能泛化到下游诊断任务，包括诊断总结和医学问答。

Result: 实验显示特定奖励优化和蒸馏能带来强路径判断性能，但向下游任务的迁移性较弱。

Conclusion: 这是对临床KG进行"奖励模型风格"推理的首次系统评估，为基于奖励的监督如何影响医疗GenAI系统中的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [11] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无需训练、无损的加速参数卸载方法，通过生成低比特量化替代层构建高度对齐的草稿模型，在内存受限的GPU上实现大语言模型的高效推理。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在内存受限GPU上部署的挑战，现有方法存在质量下降或推理速度慢的问题，需要一种既能保持质量又能加速推理的解决方案。

Method: 使用低比特量化从卸载的目标LLM部分生成替代层构建草稿模型，共享GPU驻留层和KV-Cache，减少内存开销并增强对齐度。

Result: 在8GB VRAM限制下，Qwen2.5 7B在MT-Bench上实现9.1倍加速；在24GB VRAM限制下，Qwen2.5 32B在流行生成基准测试中平均实现12.5倍加速。

Conclusion: SubSpec提供了一种有效的插拔式解决方案，通过高度对齐的草稿模型实现显著加速，解决了参数卸载中的推理瓶颈问题。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [12] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: Speech Vecalign是一种不依赖文本转录的并行语音文档对齐方法，通过单调对齐语音段嵌入，相比基线方法能产生更长的语音到语音对齐，且噪声更少。


<details>
  <summary>Details</summary>
Motivation: 现有的语音挖掘方法如Global Mining和Local Mining在对齐质量和鲁棒性方面存在不足，需要一种更有效的并行语音文档对齐方法。

Method: Speech Vecalign通过单调对齐语音段嵌入来实现语音文档对齐，不依赖文本转录，直接处理语音信号。

Result: 在3000小时的未标记英语-德语平行语音数据上应用，获得了约1000小时的高质量对齐。基于对齐数据训练的语音到语音翻译模型在En-to-De和De-to-En任务上分别比Global Mining提升了0.37和0.18 ASR-BLEU，且使用8倍少的原始语音文档就能达到或超过SpeechMatrix模型的性能。

Conclusion: Speech Vecalign是一种有效的语音文档对齐方法，能够显著提升语音到语音翻译的性能，且数据效率更高。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [13] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 提出一个LLM辅助的说话人日志校正系统，通过实时用户反馈来修正说话人归属错误，结合流式ASR和说话人日志，使用LLM生成简洁摘要并接受语音反馈。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统以"开环"模式运行，缺乏用户反馈，而人在环的工作流程可以显著提高准确性。

Method: 采用流式ASR和说话人日志，使用LLM生成摘要，接受用户语音反馈。开发了拆分合并时分割(SWM)技术来检测和分割多说话人段，以及基于用户校正的在线说话人注册。

Result: 在AMI测试集上的LLM驱动模拟显示，系统显著降低了DER 9.92%和说话人混淆错误44.23%。

Conclusion: 该系统通过实时用户反馈和在线说话人注册，有效提高了说话人日志的准确性，在不同设置下都表现出良好的校正效果。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [14] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化框架，用于生成和标注英语、中文和韩语的社会基础对话，通过Violation-to-Resolution对话类型建模规范违反后的对话进展，并采用基于范例的迭代优化提升语言一致性。


<details>
  <summary>Details</summary>
Motivation: 社会规范在沟通中决定文化适宜行为，使对话系统能够生成不仅连贯且社会可接受的回应。现有方法主要关注静态规范分类，缺乏对规范违反后对话动态的建模。

Method: 提出Violation-to-Resolution对话类型，建模规范违反后的识别和修复过程；实施基于范例的迭代优化，在对话合成早期引入语言、情感和社会文化期望的对齐；构建包含10,800个多轮对话的数据集，标注规范遵守、说话者意图和情感回应。

Result: 人类和LLM评估显示，NormGenesis在优化质量、对话自然度和泛化性能上显著优于现有数据集；使用V2R增强数据训练的模型在伦理敏感情境中表现出更好的语用能力。

Conclusion: 本研究为文化自适应对话建模建立了新基准，并为跨语言和文化的规范感知生成提供了可扩展的方法论。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [15] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 评估大型语言模型生成波斯文学文本的能力，特别是包含文化相关表达和文学手法的创造力表现


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注英语文学创作，缺乏对非英语文学传统的探索，且没有标准化的创造力评估方法。本文旨在填补波斯文学领域的空白

Method: 构建包含20个主题的波斯文学数据集，采用托兰斯创造力测试的四个维度（原创性、流畅性、灵活性、精细度）进行评估，使用LLM作为自动评分工具并与人工评分进行可靠性验证

Result: LLM评分与人工评分具有强一致性，模型在理解和运用四种核心文学手法（明喻、隐喻、夸张、对比）方面表现出既有优势也有局限

Conclusion: LLM在波斯文学文本生成方面展现出潜力，但仍需进一步改进，特别是在文化相关性和文学技巧运用方面

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [16] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种基于语言模型和对话对齐分数的自动化方法，用于大规模测量医患共享决策。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏自动化测量医患共享决策的方法，需要开发可扩展的评估工具来促进以患者为中心的护理。

Method: 使用157个医患对话视频转录的42,559个句子，通过上下文-响应对和负采样训练深度学习模型和微调BERT模型，计算四种对话对齐分数，并与SDM结果进行关联分析。

Result: 深度学习模型和微调BERT模型生成的对话对齐分数与OPTION12和决策冲突量表显著相关，BERT模型大小不影响这种关联。

Conclusion: 本研究提出了一种自动化、可扩展的方法，通过可解释的对话对齐分数来测量医患共享决策，具有大规模评估SDM策略的潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [17] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: CogniLoad是一个基于认知负荷理论(CLT)的合成基准测试，用于精确分析LLM长上下文推理能力的失败原因，通过独立调节内在难度、干扰因素比例和任务长度三个维度来评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的长上下文推理基准测试往往混淆了内在任务复杂性、干扰因素影响和任务长度等关键因素，无法进行精确的失败分析。

Method: 基于认知负荷理论构建自然语言逻辑谜题，独立调节三个核心维度：内在难度(d)控制内在负荷，干扰-信号比(ρ)调节外部负荷，任务长度(N)作为相关负荷的代理指标。

Result: 评估22个最先进的推理LLM，发现任务长度是主要约束因素，模型对内在复杂性有不同容忍度，对干扰因素比例呈现U型响应。

Conclusion: CogniLoad通过系统控制认知负荷维度，为剖析LLM推理局限性和指导未来模型开发提供了可重现、可扩展且诊断丰富的工具。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [18] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种线性注意力框架，通过将预训练transformer的能力高效转移到线性注意力架构中，解决了transformer二次计算复杂度的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: Transformer架构虽然性能优异，但其二次计算复杂度在长序列应用中成为显著瓶颈。现有线性复杂度替代方案训练成本高，需要更高效的迁移方法。

Method: LAWCAT整合因果Conv1D层增强局部依赖建模，采用归一化门控线性注意力提升不同上下文长度的泛化能力，通过知识蒸馏将预训练transformer能力转移到线性架构。

Result: 仅用1K长度序列蒸馏Mistral-7B，在22K tokens内实现90%以上passkey检索准确率；Llama3.2-1B LAWCAT变体在多个长上下文任务中表现优异，预训练token需求不到0.1%；在8K以上序列中预填充速度优于FlashAttention-2。

Conclusion: LAWCAT为高性能长上下文线性模型提供了高效路径，适合边缘部署，减少了对大量长序列训练数据和计算资源的依赖。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [19] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 该论文系统评估了LLM在图数据上的能力，发现代码生成方法表现最佳，特别是在长文本或高度图数据上，且所有交互策略在异质图中都有效，挑战了LLM方法在低同质性下失效的假设。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在文本丰富的图机器学习任务中的应用增加，领域缺乏对LLM与图数据交互能力的系统性理解，需要评估不同交互模式、数据集、结构特征等因素的影响。

Method: 通过大规模控制实验，评估LLM-图交互模式（提示、工具使用、代码生成）、数据集领域、结构机制、特征特征和模型配置等多个关键变量，并分析对输入类型的依赖关系。

Result: 代码生成方法在图数据上表现最强，特别是在长文本或高密度图上；所有交互策略在异质图中都有效；代码生成能灵活调整对结构、特征或标签的依赖以利用最信息丰富的输入类型。

Conclusion: 研究提供了当前LLM-图交互模式的全面视图，强调了未来方法的关键设计原则，特别是代码生成方法的优势和在异质图中的有效性。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [20] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种使用ByT5模型在阿拉伯诗歌中插入短语以符合特定韵律的方法，通过基于规则的音素到节拍转换和条件去噪目标训练，实现了高韵律对齐和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自动在阿拉伯诗歌中插入短语以符合特定韵律的技术，用于古典阿拉伯诗歌创作过程中的协同创作应用。

Method: 使用基于规则的音素到节拍转换提取韵律，采用条件去噪目标微调ByT5模型，使用课程学习策略（先在通用阿拉伯数据集上预训练，后在诗歌数据集上微调），并探索从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，所提出的模型在保持语义连贯性的同时实现了高韵律对齐。

Conclusion: 该模型有潜力在古典阿拉伯诗歌创作过程中用于协同创作应用。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [21] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 提出了一种轻量级框架，通过分析文本内部结构来检测原始和PSP修改的AI生成文本，解决了现有词级检测器对改写敏感、存在偏见等问题。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛使用引发了对AI生成文本滥用的担忧，现有词级检测器容易受到改写攻击，存在ChatGPT词级模式偏见，对修改文本性能下降，且需要大模型或在线LLM交互。

Method: 使用预训练语言模型编码句子嵌入，通过注意力机制建模句子间关系，采用对比学习缓解自回归生成带来的嵌入偏见，并结合因果图和反事实方法从主题相关偏见中分离结构特征。

Result: 在两个精心策划的数据集（包括摘要比较和修订的生活FAQ）上的实验验证了该方法的有效性。

Conclusion: 该方法通过关注文本内部结构特征，提供了一种对词级修改具有鲁棒性的轻量级AI文本检测解决方案。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [22] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 本文提出CCQA方法，通过循环一致性原理改进小型语言模型在推理任务中的表现，在数学和常识推理基准测试中优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有推理策略在大语言模型上有效，但在小型模型上效果不佳，需要专门针对小型模型的高效推理方法。

Method: CCQA方法基于循环一致性原理：从每个推理路径和答案生成问题，通过与原问题的相似度评估，选择得分最高的候选方案作为最终答案。使用专门的Flan-T5模型支持问题生成。

Result: 在8个模型上的实验验证，CCQA在数学和常识推理基准测试中一致优于现有SOTA方法。

Conclusion: CCQA为小型语言模型建立了新的高效推理基准，具有实际应用价值。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [23] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 提出了一种基于先验的数据过滤方法，使用语料库级别的词频统计来估计标记先验，作为困惑度（PPL）过滤的快速替代方案，在保持性能的同时大幅降低时间成本。


<details>
  <summary>Details</summary>
Motivation: 虽然基于困惑度的过滤方法表现良好，但存在时间成本高和处理噪声或分布外样本时模型不可靠的问题，需要一种更高效可靠的数据选择方法。

Method: 基于语言学的词角色和词汇密度洞察，使用语料库级别的词频统计来估计标记先验，通过标记先验的均值和标准差来过滤文档，无需模型推理。

Result: 在20个下游基准测试中取得了最高平均性能，同时比基于PPL的过滤方法减少超过1000倍的时间成本，并能适应符号语言（如代码和数学）和多语言语料库。

Conclusion: 先验过滤方法是一种简单而强大的替代方案，能够有效平衡数据过滤的效率与性能，具有广泛的应用潜力。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [24] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新型参数高效微调方法，结合数据质量选择和敏感度感知的低秩适配，提高微调效率同时保持或提升性能


<details>
  <summary>Details</summary>
Motivation: 完全微调大模型参数计算成本高且内存密集，现有参数高效方法忽视了不同模型层的敏感度差异和训练数据质量的重要性

Method: 包含两个主要组件：质量感知采样机制选择最有信息量的训练数据，以及动态秩分配模块根据层敏感度调整每层的秩

Result: 实验结果表明TsqLoRA在各种NLP任务上提高了微调效率，同时保持甚至改善了性能

Conclusion: TsqLoRA通过数据质量选择和敏感度感知的秩分配，为资源受限环境下的模型微调提供了有效解决方案

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [25] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个能够同时执行基于证据的心电图解释和文本条件心电图生成任务的统一模型，通过解耦的两阶段训练方法实现心电图与文本的双向转换。


<details>
  <summary>Details</summary>
Motivation: 现有的统一模型（如GPT-5）在视觉语言任务上取得了进展，但无法正确理解心电图信号并提供准确的医疗诊断，也不能生成心电图信号。

Method: 采用解耦的两阶段训练方法：第一阶段学习基于证据的解释技能（ECG-to-Text），第二阶段通过潜在空间对齐注入心电图生成能力（Text-to-ECG）。

Result: UniECG能够根据用户输入自主选择解释或生成心电图，显著扩展了当前心电图模型的能力边界。

Conclusion: UniECG作为首个心电图统一模型，成功实现了心电图与文本的双向转换，代码和检查点将在接受后公开。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [26] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 研究发现用户偏好和模型偏好并不能准确预测哪些计划真正对用户有帮助，常用的对齐方法可能误导LLM的有用性，需要基于真实用户交互的反馈而非表面偏好。


<details>
  <summary>Details</summary>
Motivation: 测试LLM生成计划的有用性与用户偏好之间的关系，验证当前基于偏好的对齐方法是否能真正反映计划对用户的帮助程度。

Method: 使用Planorama接口，让126名用户回答300个多步问题，收集4388个计划执行和5584个比较数据，测量计划有用性和用户偏好，并在代理和奖励模型中重现实验设置。

Result: 1) 用户/模型偏好和代理成功率不能准确预测计划对用户的有用性；2) 这种差距不是用户特定偏好造成的；3) 表面特征如简洁性和问题相似性与偏好强相关，但不能预测有用性。

Conclusion: 需要基于真实用户交互的反馈来对齐有用的LLM，而不仅仅是看起来有用的偏好，并讨论了解决此问题的研究路径。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [27] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: CAPE-KG是一个基于知识图谱的一致性感知参数保持知识编辑框架，用于解决多跳问答中的知识编辑一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的参数保持知识编辑方法在多跳问答中存在一致性问题，导致知识污染、更新不稳定和检索行为与编辑意图不符，影响了多跳推理的可靠性。

Method: 提出CAPE-KG框架，确保知识图谱的构建、更新和检索始终与多跳问答任务要求对齐，保持对未编辑和已编辑知识的一致推理。

Result: 在MQuAKE基准测试上的广泛实验显示，CAPE-KG在多跳问答的PPKE性能上实现了准确率提升。

Conclusion: 通过解决一致性问题，CAPE-KG有效提升了参数保持知识编辑在多跳问答中的可靠性。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [28] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 该论文提出了第一个通过保形预测分析LLM作为评判者不确定性的框架，为LLM评分提供预测区间，并设计了针对离散评分任务的序数边界调整方法。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者的评估范式虽然前景广阔，但其评估的不确定性尚未得到充分探索，这种可靠性不足可能限制其在许多应用中的部署。

Method: 使用保形预测方法构建连续预测区间，设计序数边界调整来处理离散评分任务，并提出基于区间中点的评分作为原始模型评分和加权平均的低偏差替代方案。

Result: 广泛的实验和分析表明，保形预测能够提供具有覆盖保证的有效预测区间，区间中点和评判者重新提示对改善判断效果有用。

Conclusion: 该框架为LLM评估提供了可靠的不确定性量化方法，有助于提升LLM作为评判者在自然语言生成评估中的可信度和实用性。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [29] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: MemOrb是一个轻量级、即插即用的语言强化记忆层，通过将多轮交互提炼为紧凑的策略反思，存储在共享记忆库中，无需微调即可指导决策，显著提升LLM智能体在客服场景中的成功率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体在客服应用中存在跨会话遗忘、重复错误和缺乏持续自我改进机制的问题，导致在动态环境中不可靠，需要提升稳定性和一致性。

Method: 提出MemOrb记忆层，通过提炼多轮交互的策略反思并存储在共享记忆库中，在决策时检索相关反思进行指导，无需模型微调。

Result: 实验显示MemOrb显著提高了任务成功率和稳定性，多轮成功率提升高达63个百分点，在重复试验中表现更一致。

Conclusion: 结构化反思是增强冻结LLM智能体在客服场景中长期可靠性的有效机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [30] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: LOTUSDIS是一个公开的泰语会议语料库，包含114小时自发对话，用于推进远场对话语音识别研究。该数据集通过多种麦克风在不同距离录制，包含重叠语音和真实声学效应。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练模型在泰语远场语音识别上表现不佳，存在数据不匹配问题。需要距离多样化的训练数据来提升ASR系统的鲁棒性。

Method: 收集114小时自发泰语对话，使用9个独立单通道设备（6种麦克风类型）在0.12-10米距离同时录制。提供标准数据集划分和可复现的基线系统，对Whisper模型进行零样本和微调测试。

Result: 零样本模型随距离增加性能显著下降。微调后，泰语Whisper基线整体WER从64.3降至38.3，远场WER从81.6降至49.5，最远麦克风上改进最大。

Conclusion: 距离多样化的训练数据对鲁棒ASR至关重要。LOTUSDIS语料库和基线系统可促进该领域可复现研究。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [31] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: DyGRASP是一种处理动态文本属性图的新方法，结合LLM和时序GNN，有效捕捉近期和全局时间语义，在节点检索任务上提升34%性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注静态文本属性图，难以处理时间演化的动态图，且忽略了近期-全局时间语义，同时LLM在处理大量动态文本时存在效率问题

Method: 设计节点中心隐式推理和滑动窗口机制捕捉近期语义；利用显式推理和RNN链结构捕获全局语义动态；通过更新和融合层整合近期/全局语义与图结构信息

Result: 在DyTAG基准测试中，DyGRASP在目标节点检索任务的Hit@10指标上提升达34%，且在不同时序GNN和LLM上表现出强泛化能力

Conclusion: DyGRASP通过有效整合近期和全局时间语义，解决了动态文本属性图处理的关键挑战，为时序图学习提供了新的解决方案

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [32] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本文研究了多语言模型中子词标记重叠对跨语言迁移的影响，通过控制实验发现标记重叠有利于跨语言语义关系的捕获和迁移性能的提升。


<details>
  <summary>Details</summary>
Motivation: 多语言标记器自然会产生跨语言重叠的标记，但现有研究对标记重叠是促进跨语言迁移还是引入干扰存在争议，部分原因是实验设置和混杂因素（如标记频率、子词分割粒度）的差异。

Method: 设计了受控实验，在多个语言对上训练双语自回归模型，系统性地改变词汇重叠设置，并探索了新的维度：跨语言共享标记的语义相似性。分析了模型的隐藏表示，并在XNLI和XQuAD上评估迁移性能。

Result: 发现任何类型的重叠都会创建捕获跨语言语义关系的嵌入空间，而词汇不相交的模型这种效应较弱。在XNLI和XQuAD上，有重叠的模型表现优于词汇不相交的模型，且随着重叠增加，迁移性能普遍提升。

Conclusion: 标记重叠在多语言模型中具有优势，大量共享词汇仍然是多语言标记器的有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [33] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 本文研究发现，与长上下文预训练导致短上下文任务性能下降的常见现象相反，长上下文监督微调（SFT）反而能提升LLM在短上下文任务上的表现。通过分析MHA和FFN组件，揭示了长上下文SFT促进上下文知识、短上下文SFT偏好参数知识的偏差，并提出混合训练方法进行优化。


<details>
  <summary>Details</summary>
Motivation: 随着实际应用对长上下文窗口的需求增加，长上下文数据的持续预训练和SFT成为常见方法。虽然持续预训练中数据长度的影响已被广泛研究，但其对SFT的影响尚不明确。

Method: 系统研究SFT数据长度如何影响LLM在短上下文任务上的行为；解耦分析多头注意力（MHA）和前馈网络（FFN）组件；研究它们的相互作用并揭示知识偏好偏差；提出混合训练方法。

Result: 发现长上下文SFT能提升短上下文性能；MHA和FFN都独立受益于长上下文SFT；长上下文SFT促进上下文知识，短上下文SFT偏好参数知识；混合训练能缓解这种偏差。

Conclusion: 长上下文SFT对短上下文任务有积极影响，但单独依赖长上下文SFT存在知识偏好偏差问题，混合训练提供了可解释的LLM微调指导。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [34] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 提出一种基于10-K财务文件的无监督方法，用于提取企业间风险关系，解决传统专家判断的主观性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统依赖专家判断和手动分析来识别企业间风险关系的方法存在主观性强、劳动密集且难以扩展的问题，需要系统化的自动解决方案。

Method: 利用自然语言处理技术，基于10-K文件的时序和词汇模式进行无监督微调，开发领域特定的金融编码器，并引入可量化的风险关系评分。

Result: 大量实验表明，该方法在多个评估场景下均优于强基线模型。

Conclusion: 该方法能够有效捕获隐含和抽象的风险联系，为投资组合管理和投资策略等应用提供透明、可解释的分析工具。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [35] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本文建立了AECBench基准测试，用于评估大语言模型在建筑、工程和施工领域的性能表现，揭示了模型在复杂推理和计算等高级认知任务上的显著局限性


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在AEC领域的应用日益增多，需要评估这些模型在安全关键领域的鲁棒性和可靠性

Method: 构建包含23个代表性任务的五级认知评估框架，创建4800个问题的数据集，采用LLM-as-a-Judge方法进行可扩展评估

Result: 评估9个LLM显示，模型在知识记忆和理解层面表现良好，但在表格解释、复杂推理计算和领域文档生成方面存在显著性能缺陷

Conclusion: 该研究为未来将LLM可靠集成到安全关键工程实践中奠定了基础

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [36] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 该论文使用模型差异分析（model diffing）方法比较Gemma-2-9b-it模型与其SimPO增强变体，发现SimPO主要增强了安全性、多语言能力和指令遵循能力，同时减少了模型自引用和幻觉管理。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大型语言模型的主要方法，传统基准测试往往无法解释模型性能差异的原因，需要更深入的分析方法来理解微调过程中的具体变化。

Method: 采用模型差异分析（一种机制可解释性方法），使用crosscoders识别和分类两个模型之间的潜在表示差异。

Result: SimPO获得的潜在概念主要增强了安全性机制（+32.8%）、多语言能力（+43.8%）和指令遵循（+151.7%），同时减少了模型自引用（-44.1%）和幻觉管理（-68.5%）的强调。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度洞察，将性能差距归因于具体的机制能力，为比较LLMs提供了透明和有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [37] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是一个基于多智能体协作的关键词提取框架，通过动态适应文档长度的双路径策略，显著提升了LLM在关键词提取任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督提示方法通常采用单阶段推理管道和统一提示策略，无法充分利用LLM的推理和生成能力，特别是在处理不同长度文档时表现不佳。

Method: MAPEX引入多智能体协作框架，包含专家招募、候选提取、主题指导、知识增强和后处理模块，采用双路径策略：短文本使用知识驱动提取，长文本使用主题引导提取。

Result: 在六个基准数据集和三种不同LLM上的实验表明，MAPEX在F1@5指标上平均优于最先进的无监督方法2.44%，优于标准LLM基线4.01%。

Conclusion: MAPEX通过多智能体协作和动态适应策略，有效提升了关键词提取的性能和泛化能力，为LLM在复杂NLP任务中的应用提供了新思路。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [38] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本研究表明，在生物医学问答领域，开源大语言模型（如DeepSeek-V3）的性能可与闭源专有模型（如GPT-4o、Claude 3.5等）相媲美，甚至在集成策略下表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着开源大语言模型的快速发展，研究者希望验证小型开源模型是否能够有效替代大型闭源模型，特别是在生物医学问答这一专业领域。

Method: 采用检索相关片段、上下文学习、结构化输出等技术，并对精确答案问题使用集成方法整合不同模型的输出。在BioASQ挑战赛的Task 13B Phase B中进行评估。

Result: 实验结果显示，开源大语言模型与专有模型性能相当，在某些情况下（特别是应用集成策略时）甚至超越了闭源模型。

Conclusion: 开源大语言模型在生物医学问答任务中具有与闭源模型竞争的能力，证明了开源模型的实用价值和替代潜力。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [39] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 本文系统研究了多特征集成在AI文本检测中的效果，发现尽管理论上多特征应提供互补信号，但实际仅带来微小性能提升(0.4-0.5%)，同时计算成本显著增加(4.2倍)，表明现代神经网络可能已高效捕捉了大部分相关检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型技术的快速发展，研究者对多特征方法是否能显著超越单一神经网络模型在AI文本检测方面的性能产生兴趣。虽然直觉上语义、句法和统计特征的组合应提供互补信号，但这一假设尚未在现代LLM生成文本上得到严格测试。

Method: 实现MHFD(多层次特征检测)方法，通过自适应融合集成基于DeBERTa的语义分析、句法解析和统计概率特征。

Result: 在多个基准数据集上的实验结果表明，MHFD方法在域内检测中达到89.7%的准确率，在跨域检测中保持84.2%的稳定性能，相比现有方法有0.4-2.6%的适度提升。

Conclusion: 多特征集成带来的收益微乎其微，而计算成本显著，表明现代神经语言模型可能已经高效地捕捉了大部分相关检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [40] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: DivEye是一个基于意外性特征的新型AI文本检测框架，通过捕捉文本中不可预测性的波动来区分人类写作和AI生成内容。


<details>
  <summary>Details</summary>
Motivation: 现有检测器依赖词级似然度或不透明的黑盒分类器，难以应对高质量生成文本且缺乏可解释性。人类写作在词汇和结构不可预测性上比AI输出展现出更丰富的变异性。

Method: DivEye使用基于意外性的可解释统计特征来捕捉文本中不可预测性的波动模式，分析人类写作与AI生成文本在不可预测性节奏上的差异。

Result: DivEye在多个基准测试中比现有零样本检测器性能提升达33.2%，与微调基线模型表现相当，对改写和对抗攻击具有鲁棒性，跨领域和模型泛化能力强，作为辅助信号可将现有检测器性能提升18.7%。

Conclusion: DivEye不仅提供有效的AI文本检测，还通过可解释的洞察揭示了节奏不可预测性作为LLM检测的强大且未被充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [41] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一个仅使用编码器的架构，联合执行提取式原子事实分解和可解释推理，无需在推理时使用生成模型，在NLI任务中实现了竞争性准确性并显著提高了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖资源密集型的生成式大语言模型进行原子事实分解，这影响了效率和可扩展性。作者希望开发一种更高效的替代方案。

Method: 提出JEDI编码器架构，联合执行提取式原子事实分解和可解释推理。使用合成理性语料库进行训练，涵盖多个NLI基准测试。

Result: JEDI在分布内任务中达到竞争性准确率，在分布外和对抗性设置中显著提高了鲁棒性，优于仅基于提取式理性监督的模型。

Conclusion: 研究表明，使用仅编码器架构和合成理性可以在NLI中实现可解释性和鲁棒泛化，为高效可解释推理提供了新途径。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [42] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态时间规整（DTW）的端到端语音翻译方法，用于更准确地对齐语音和文本表示，解决了现有方法需要语言特定对齐工具的限制。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译中，语音和文本模态之间的表示差异（模态鸿沟）是主要挑战。现有方法需要语言特定的对齐工具，这在许多语言中不可用，而基于最近邻相似度搜索的方法对齐不准确。

Method: 在训练过程中使用动态时间规整（DTW）来对齐语音和文本嵌入表示，无需语言特定的对齐工具，能够更准确地建立语音和文本之间的对应关系。

Result: 相比之前的工作，该方法产生更准确的对齐结果，在端到端语音翻译任务上取得可比性能，且速度显著更快。在低资源场景下，6个语言方向中有5个表现优于之前的方法。

Conclusion: 基于DTW的对齐方法有效解决了端到端语音翻译中的模态鸿沟问题，特别是在缺乏对齐工具的语言和低资源场景下表现出色，为多语言语音翻译提供了实用解决方案。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [43] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了机器翻译中的测试时缩放（TTS）方法，通过最佳N选择框架在WMT24基准测试上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统通过增加模型参数规模来提升NLP系统性能的方法计算成本高昂，测试时缩放（TTS）通过在推理时生成多个候选并选择最佳结果，提供了一种替代方案。

Method: 采用简单实用的最佳N选择框架，在WMT24基准上测试了6个高资源和1个低资源语言对，涵盖5种模型规模（3B-72B）和多种TTS计算预算（N最大1024）。

Result: 对于高资源语言，TTS能显著提升翻译质量；小模型通过大N值可以匹配或超越大模型N=1的性能；在固定计算预算下，大模型通常更高效，但在低资源情况下TTS可能因评估指标盲点而降低质量。

Conclusion: TTS为机器翻译提供了一种有效的性能提升策略，特别是在高资源语言场景下，但需要根据具体场景权衡计算成本与性能增益。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [44] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本文通过分析意大利计算语言学和自然语言处理领域的主要会议CLiC-it过去10年的论文集，追踪了该领域的研究趋势演变，重点关注从词汇语义资源到语言建模和多模态研究的转变。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer大语言模型的出现，计算语言学和自然语言处理领域经历了快速演变。本研究旨在通过分析意大利CL/NLP社区的研究成果，了解该领域的研究趋势变化，为研究社区提供有价值的见解。

Method: 收集CLiC-it会议2014-2024年共10届的论文集，构建CLiC-it语料库，对论文元数据（作者来源、性别、机构等）和内容进行综合分析。

Result: 创建了包含10年会议论文的完整语料库，提供了意大利CL/NLP研究社区的全面分析，揭示了研究重点从传统资源向语言建模和多模态的转变。

Conclusion: 该研究为意大利和国际研究社区提供了关于领域发展趋势的重要洞察，支持该领域的明智决策和未来发展方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [45] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 提出了Pathways of Thoughts (PoT)方法，通过建模LLM的推理为迭代决策过程，在推理阶段实现个性化问答，无需任务特定微调，在LaMP-QA基准上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 个性化问答系统对提升准确性和用户满意度至关重要，但面临从长、嘈杂、隐式上下文中推断偏好以及生成同时正确、上下文适当且符合用户期望的响应的挑战。

Method: PoT方法将LLM推理建模为迭代决策过程，动态选择推理、修订、个性化和澄清等认知操作，探索多种推理轨迹，生成多样化候选响应，然后根据推断的用户偏好进行聚合和重加权。

Result: 在LaMP-QA基准上的实验显示，PoT持续优于竞争基线，相对改进高达13.1%。人工评估中，注释者在66%的情况下偏好PoT输出，仅在15%的情况下报告平局。

Conclusion: PoT作为一种推理阶段方法，能够有效提升个性化问答性能，通过多样化推理路径的互补优势生成更符合用户期望的响应。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [46] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 本文通过分析不同语料库中的句子重复率，实证检验了语言学中关于大多数语言表达都是独特的这一论断。


<details>
  <summary>Details</summary>
Motivation: 语言学中普遍认为大多数语言表达都是独特的，但随着大型语料库的可用性增加，这一论断需要实证验证。

Method: 使用NLTK Python库解析不同体裁的语料库，统计每个语料库中完全相同的字符串匹配数量。

Result: 结果显示，虽然完全独特的句子在语料库中通常占多数，但这高度受体裁限制，重复句子在任何单个语料库中都不是微不足道的部分。

Conclusion: 语言表达的独特性受体裁影响显著，重复句子在语言使用中占有重要地位，挑战了传统语言学关于语言表达独特性的绝对论断。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [47] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzNER，这是首个为吉尔吉斯语手动标注的命名实体识别数据集，包含1,499篇新闻文章、10,900个句子和39,075个实体提及，涵盖27个实体类别。


<details>
  <summary>Details</summary>
Motivation: 为资源有限的吉尔吉斯语创建首个高质量的命名实体识别数据集，以支持该语言的NLP研究和发展。

Method: 构建包含27个实体类别的标注方案，评估了基于条件随机场的传统序列标注方法和基于多语言transformer模型（如RoBERTa）的先进方法。

Result: 所有模型在罕见实体类别上都表现困难，但多语言RoBERTa变体在精确率和召回率之间取得了有希望的平衡，其他多语言模型也获得了可比较的结果。

Conclusion: 多语言预训练模型在处理资源有限语言方面既有挑战也有机会，未来探索更细粒度的标注方案可能为吉尔吉斯语处理管道评估提供更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [48] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新的上下文感知分层分类法生成框架，结合LLM引导的多方面编码和动态聚类，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长需要高效组织方法，现有分类法构建方法缺乏连贯性和粒度

Method: 利用LLM识别论文关键方面并生成方面特定摘要，然后进行编码和聚类形成层次结构

Result: 实验结果表明该方法在分类法连贯性、粒度和可解释性方面达到最先进性能

Conclusion: 该方法为科学文献组织提供了有效的解决方案，并创建了首个自然标注数据集用于评估

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [49] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 提出了一种名为'anecdoctoring'的新型红队测试方法，用于在多语言和多文化背景下自动生成对抗性提示，以评估生成式AI在虚假信息传播方面的风险。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的滥用风险中，虚假信息是主要威胁之一。当前的红队测试数据集通常以美国英语为中心，缺乏对不同语言和文化的覆盖，无法有效评估全球范围内的AI风险。

Method: 从英语、西班牙语和印地语的事实核查网站收集虚假信息声明，将其聚类为更广泛的叙事，并使用知识图谱来增强攻击者LLM的能力，从而自动生成跨语言和文化的对抗性提示。

Result: 与少样本提示相比，该方法在攻击成功率上表现更高，并提供了更好的可解释性。

Conclusion: 研究结果强调了需要开发能够全球扩展并基于真实世界对抗性滥用的虚假信息缓解措施。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [50] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文提出了AI "slop"（低质量AI生成文本）的分类体系，通过专家访谈开发了可解释的评估维度，并发现二元判断具有一定主观性但能与潜在维度相关


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对AI "slop"的统一定义和测量方法，需要建立系统的评估框架

Method: 通过NLP、写作和哲学领域的专家访谈开发分类体系，进行span级标注分析二元判断与潜在维度的相关性

Result: 发现二元"slop"判断具有主观性，但与连贯性和相关性等潜在维度存在相关性

Conclusion: 该框架可用于AI生成文本的检测和偏好评估任务，为质量判断的语言和风格因素提供新见解

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [51] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文提出了一种通过强化学习（RL）学习连续思维链（CoT）的可扩展方法，无需从离散CoT中蒸馏。使用"软"令牌（令牌混合和输入嵌入噪声）实现RL探索，计算开销最小，可学习数百个令牌的连续CoT。


<details>
  <summary>Details</summary>
Motivation: 连续令牌在推理LLMs的思维链阶段具有比离散令牌更强的表达能力，能更高效解决特定问题。但现有方法存在训练困难：要么仅在预训练离散模型上推理时使用连续令牌，要么必须从真实离散CoT中蒸馏且计算成本高。

Method: 采用强化学习方法学习连续CoT，使用"软"令牌（令牌混合和输入嵌入噪声）进行RL探索。计算开销小，可处理数百个令牌的连续CoT。

Result: 在Llama和Qwen模型（最大8B）的数学推理基准测试中，连续CoT训练在pass@1上匹配离散令牌CoT，在pass@32上超越，显示出更大的CoT多样性。最佳性能场景是训练使用连续CoT令牌，推理使用离散令牌。

Conclusion: 连续CoT RL训练能更好地保留基础模型在域外任务上的预测，为基模型提供更"温和"的调整。软模型可以标准方式部署。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [52] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: OPRL是一种用于智能体强化学习的通用信用分配策略，通过交替优化隐式过程奖励模型和智能体策略，将轨迹偏好转化为隐式步骤奖励，解决了稀疏奖励环境中的时间信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型作为自主智能体在交互环境中进行长期推理和行动时，稀疏且有时不可验证的奖励使得时间信用分配极具挑战性。现有方法存在标注偏差、奖励攻击、高方差等问题。

Method: OPRL通过轨迹DPO目标将轨迹偏好转化为隐式步骤奖励，然后计算步骤级优势，并与结果奖励的回合级优势结合进行策略更新，形成自增强循环。理论保证学习到的步骤奖励与轨迹偏好一致。

Result: 在WebShop、VisualSokoban和SOTOPIA等三个不同智能体基准测试中，OPRL表现出优于前沿LLM和强RL基线的性能，实现了最先进的结果，训练过程中具有更高的样本效率和更低的方差。

Conclusion: OPRL通过更少的动作实现了高效探索，展示了其在现实世界智能体学习中的潜力，为稀疏奖励环境中的信用分配提供了有效的解决方案。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [53] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: SafeCoDe是一个轻量级、模型无关的解码框架，通过对比解码和全局感知的token调制策略，动态调整多模态大语言模型的安全决策，平衡过度敏感和敏感不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在安全决策方面存在平衡问题，要么过度敏感（拒绝良性查询），要么敏感不足（错过视觉风险），需要一种能根据多模态上下文动态调整安全决策的方法。

Method: SafeCoDe采用两阶段方法：1）对比解码机制，通过对比真实图像和高斯噪声图像来识别对视觉上下文敏感的token；2）全局感知的token调制策略，将场景级推理与token级调整相结合，根据预测的安全判断自适应调整拒绝行为。

Result: 在多种MLLM架构和安全基准测试中，SafeCoDe一致改善了上下文敏感的拒绝行为，同时保持了模型的有用性。

Conclusion: SafeCoDe有效解决了多模态大语言模型在安全对齐方面的持续差距，提供了一种轻量级且模型无关的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [54] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究比较了多种预训练注意力模型在电子健康记录信息提取任务上的性能，包括Bert Base、BioBert、Bio+Clinical Bert变体、RoBerta和Clinical Longformer，使用CMED数据集进行药物提取、医疗事件检测和多维药物事件上下文分类。


<details>
  <summary>Details</summary>
Motivation: 基于注意力的模型已成为临床笔记自然语言处理的主要方法，但需要比较不同预训练模型在电子健康记录信息提取任务上的有效性，特别是针对药物相关事件的处理。

Method: 使用哈佛医学院2022年n2c2挑战赛Track 1的任务和CMED数据集，对多个预训练模型进行微调，进行药物提取、医疗事件检测和上下文分类，并详细描述了处理EHR数据的方法。

Result: 结果显示，在临床数据上预训练的模型在检测药物和药物事件方面更有效，但Bert Base（在通用领域数据上预训练）在分类药物相关事件的上下文方面表现最佳。

Conclusion: 虽然临床预训练模型在检测任务上表现更好，但通用预训练模型在上下文分类任务上具有优势，表明不同模型在不同类型的医疗NLP任务中各有优势。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [55] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种针对长上下文处理的软压缩技术，通过分段独立压缩实现线性复杂度、可扩展性和可重用性，在保持性能的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM处理长上下文时面临二次复杂度的计算挑战，现有软压缩方法将整个上下文作为单一单元压缩，导致二次压缩复杂度且无法重用重叠上下文的计算。

Method: 将上下文分割成独立段进行压缩，而非整体处理。这种设计使压缩步骤随上下文长度线性扩展，支持短序列训练模型泛化到长上下文，并允许压缩段缓存重用。

Result: 在2倍压缩率下，CompLLM在高上下文长度时将首令牌时间加速最高4倍，KV缓存减少50%，性能与未压缩上下文相当，在超长序列上甚至表现更优。

Conclusion: CompLLM通过分段压缩设计实现了高效、可扩展和可重用的长上下文处理，展示了实际部署的实用性和有效性。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [56] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的训练时扩展范式，通过强化学习在预训练数据上优化大语言模型，无需人工标注奖励信号，直接从预训练数据中获取奖励，提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 计算资源指数级增长与高质量文本数据有限增长之间的差距制约了传统大语言模型的扩展方法，需要新的训练范式来突破这一瓶颈。

Method: 采用下一段推理目标，让策略基于前文准确预测后续文本片段来获得奖励，使强化学习能够在预训练数据上规模化应用，探索更丰富的轨迹。

Result: 在多个模型和基准测试上验证了RLPT的有效性，Qwen3-4B-Base模型在MMLU、MMLU-Pro等基准上获得显著提升，显示出良好的扩展潜力。

Conclusion: RLPT扩展了大语言模型的推理边界，为强化学习提供了坚实基础，具有持续增益的潜力。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [57] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型中提取概念空间的方法，通过使用原型描述来编码特征，并对LLM进行微调以对齐原型嵌入与概念空间维度。


<details>
  <summary>Details</summary>
Motivation: 概念空间使用认知上有意义的维度来表示实体和概念，在认知科学中广泛应用，并有望成为可解释AI的基石。然而，目前缺乏从LLMs中提取概念空间的实用方法。

Method: 提出一种策略：通过嵌入相应原型的描述来编码特征（如甜度），并对LLM进行微调，使原型嵌入与概念空间维度对齐。

Result: 实证分析发现该方法非常有效。

Conclusion: 该方法成功解决了从LLMs中提取概念空间的难题，为可解释AI提供了实用工具。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [58] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 该论文介绍了SloPalSpeech——一个包含2,806小时斯洛伐克议会语音的大规模ASR数据集，通过微调Whisper模型显著降低了斯洛伐克语的词错误率。


<details>
  <summary>Details</summary>
Motivation: 解决斯洛伐克语等低资源语言在自动语音识别中因训练数据稀缺而面临的挑战。

Method: 开发了稳健的处理流程，将长格式录音对齐并分割成30秒的音频-文本对，用于微调多个OpenAI Whisper模型。

Result: 微调后的Whisper-small模型词错误率降低了高达70%，接近更大模型Whisper-large-v3的基线性能。

Conclusion: 公开发布完整的SloPalSpeech数据集、分割后的转录文本（6000万字）和所有微调模型，以促进低资源语音识别的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [59] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 该论文发布了沃洛夫语意图分类数据集WolBanking77，包含9,791条银行领域文本句子和超过4小时的语音数据，旨在解决低资源语言意图分类的研究空白。


<details>
  <summary>Details</summary>
Motivation: 现有意图分类研究主要关注高资源语言，而沃洛夫语等低资源语言存在研究空白，特别是在塞内加尔等文盲率较高的地区，口语比书面语更常用。

Method: 构建沃洛夫语银行领域数据集，包含文本和语音数据，并在多种基线模型上进行实验，包括文本和语音的先进模型。

Result: 在该数据集上的实验结果很有前景，报告了NLP模型的F1分数和ASR模型的词错误率等基线指标。

Conclusion: 计划共享和维护数据集，发布开源代码，促进低资源语言意图分类研究的发展。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [60] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个专门针对印度文化的多模态多语言基准测试，用于评估生成式AI系统的文化理解能力，覆盖15种语言和64,000多个文本-图像对。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试多为通用性或全球性，缺乏对特定文化（如印度文化）的深度覆盖，需要专门的文化理解评估工具。

Method: 构建包含印度各地区、语言和文化主题的多模态数据集，评估各种视觉语言模型在零样本和思维链设置下的表现。

Result: 当前模型在处理文化相关的多模态输入时存在显著局限性，特别是在低资源语言和较少记录的传统方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究的重要空白，为推进文化感知的多模态语言技术提供了强大的测试平台。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文提出了一个成本效益分析框架，帮助企业决定何时本地部署开源LLM比商业订阅服务更经济可行。


<details>
  <summary>Details</summary>
Motivation: 企业面临选择商业LLM服务还是本地部署的决策困境。商业服务易用但存在数据隐私、供应商锁定和长期成本问题，而本地部署开源模型的需求日益增长。

Method: 通过分析最新开源模型的硬件需求、运营成本和性能基准，并与主要云服务商的订阅费用进行对比，建立成本效益分析框架。

Result: 研究提供了基于使用量和性能需求的盈亏平衡点估算，为企业LLM战略规划提供实用指导。

Conclusion: 该框架帮助企业根据具体需求做出经济合理的LLM部署决策，平衡成本、隐私和性能等因素。

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [62] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: SPADE是一个利用大语言模型（LLM）分析土壤湿度时间序列数据的框架，能够检测灌溉模式和异常，无需特定任务的标注或微调。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度时间序列分析方法要么依赖基于阈值的规则，要么需要大量数据的机器学习模型，适应性差且可解释性不足。

Method: SPADE使用ChatGPT-4.1，将时间序列数据转换为文本表示，通过领域知识设计的提示模板进行零样本分析，识别灌溉事件、估计净灌溉增益、检测和分类异常。

Result: 在真实农场数据上的实验表明，SPADE在异常检测方面优于现有方法，召回率和F1分数更高，灌溉事件检测精度和召回率也很高。

Conclusion: 该研究展示了LLM作为精准农业可扩展、适应性强的工具的潜力，能够整合定性知识和数据驱动推理，为土壤湿度监测和灌溉调度提供可操作的见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [63] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 本文提出了可解释不确定性估计（XUE）方法，将可解释性与不确定性量化相结合，以增强医疗AI的信任度和可用性。


<details>
  <summary>Details</summary>
Motivation: 当前医疗AI系统未能以符合临床推理的方式明确量化或传达不确定性，现有XAI工作只解释模型预测而不捕捉预测的置信度，而UE技术提供置信度但缺乏直观解释，这种脱节限制了AI在医学中的应用。

Method: 系统地将医学不确定性映射到AI不确定性概念，识别XUE实施的关键挑战，提出技术方向包括多模态不确定性量化、模型无关的可视化技术和不确定性感知的决策支持系统。

Result: 分析强调了需要开发既能生成可靠预测又能以临床有意义的方式表达置信度的AI系统。

Conclusion: 这项工作通过桥接可解释性和不确定性，为开发可信赖的医疗AI做出贡献，为与真实世界临床复杂性对齐的AI系统铺平道路。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [64] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: HSGM是一种分层分段图记忆框架，通过将长文档分解为有意义的段落，构建局部语义图并提取摘要节点来形成全局图记忆，显著降低了长文档语义解析的计算复杂度和内存需求。


<details>
  <summary>Details</summary>
Motivation: 长文档语义解析面临二次复杂度增长和内存需求激增的挑战，传统方法难以处理超长文本。

Method: HSGM将输入文档分解为M个段落，为每个段落构建局部语义图，提取摘要节点形成全局图记忆，支持增量更新和分层查询处理。

Result: 在三个基准测试中，HSGM实现了2-4倍推理加速，峰值内存减少60%以上，准确率达到基线方法的95%以上。

Conclusion: HSGM为超长文本的可扩展、准确语义建模提供了解决方案，支持实时和资源受限的NLP应用。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [65] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多智能体框架，通过单一自然语言提示自动化整个OpenFOAM工作流程，显著降低了CFD仿真的专业门槛。


<details>
  <summary>Details</summary>
Motivation: 解决CFD仿真学习曲线陡峭和手动设置复杂的问题，降低工程仿真的专业门槛。

Method: 采用多智能体框架，包含网格生成代理、HPC脚本自动生成和可视化功能；使用Model Context Protocol实现可组合服务架构；通过分层多索引RAG实现高保真配置生成。

Result: 在110个仿真任务基准测试中，使用Claude 3.5 Sonnet达到88.2%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%）。

Conclusion: Foam-Agent有效降低了CFD的专业门槛，展示了专业多智能体系统在复杂科学计算民主化方面的潜力。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [66] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本文综述了将大语言模型（LLMs）集成到运筹学（OR）中的最新进展，总结了自动建模、辅助优化和直接求解三个主要方向，并讨论了关键挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学方法依赖专家建模和手动参数调整，难以处理大规模、动态和多约束问题。LLMs通过语义理解、结构化生成和推理控制，有望解决这些局限性。

Method: 将LLMs在OR中的应用方法组织为三个方向：自动建模（将自然语言描述转换为数学模型或可执行代码）、辅助优化（生成启发式方法和演化算法）、直接求解优化任务。

Result: LLMs在OR中展现出潜力，能够提升建模效率和优化性能，但存在语义到结构映射不稳定、研究进展碎片化、泛化能力有限和评估体系不足等问题。

Conclusion: LLMs为OR提供了新的机遇，但需要解决现有挑战，未来研究应关注改进语义理解、增强泛化能力和建立更全面的评估体系。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [67] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本文提出了SAPA框架，利用大语言模型合成理论驱动的潜在态度来预测网约车选择，显著提升了预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有网约车模式选择模型预测精度有限，无法捕捉关键心理因素，且面临严重的类别不平衡问题（网约车出行仅占日常出行的小部分）。

Method: SAPA框架采用分层方法：1）使用LLM从原始出行调查数据生成定性旅行者画像；2）基于人口统计和行为特征训练倾向得分模型；3）LLM为理论驱动的潜在变量分配定量分数；4）最终分类器整合倾向得分、潜在变量分数和可观察的出行属性。

Result: 在大规模多年出行调查上的实验表明，SAPA显著优于最先进的基线方法，在测试集上的PR-AUC指标提升了高达75.9%。

Conclusion: 该研究为准确预测网约车模式选择提供了强大工具，其方法可轻松迁移到各种应用中。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [68] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: OBER是一个基于学习成果的教育推荐系统，通过将学习成果和评估项目嵌入数据模式，使任何推荐算法都能基于其促进的掌握程度进行评估。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统仅基于点击或评分相关性进行调优和评估，缺乏对其真实教学影响的清晰衡量。

Method: OBER采用极简的实体关系模型、基于日志的掌握度公式和插件架构，在非正式学习领域集成到e-learning系统中，通过为期两周的随机分组测试评估了三种方法：固定专家路径、协同过滤和基于知识的过滤。

Result: 协同过滤最大化用户留存率，但固定路径实现了最高的掌握度。OBER可以从相同日志中导出业务、相关性和学习指标。

Conclusion: OBER框架是方法无关的，可轻松扩展到未来的自适应或上下文感知推荐系统，让从业者能够在没有额外测试开销的情况下权衡相关性、参与度和成果掌握度。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [69] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 提出MMCD框架，通过多模态协作决策和跨模态知识蒸馏解决自动驾驶中传感器故障或协作车辆缺失时的鲁棒性问题


<details>
  <summary>Details</summary>
Motivation: 现有方法假设训练和测试时所有数据模态和连接车辆都可用，这不切实际，因为可能存在传感器故障或缺失协作车辆

Method: 采用教师-学生模型结构进行跨模态知识蒸馏，教师模型使用多模态数据训练，学生模型设计用于在模态减少时有效运行

Result: 在连接自动驾驶和空地车辆协作实验中，方法将驾驶安全性提高达20.7%，在潜在事故检测和安全驾驶决策方面超越现有最佳基线

Conclusion: MMCD框架通过多模态融合和知识蒸馏技术，显著提升了自动驾驶系统在挑战性环境中的鲁棒决策能力

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [70] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法来解释定量双极论证框架（QBAFs）中推理变化的原因，通过追踪论证强度部分顺序中的不一致性来识别解释。


<details>
  <summary>Details</summary>
Motivation: 在QBAF中，当更新框架并重新得出结论时，论证强度的部分顺序可能出现不一致性，需要一种系统的方法来追踪和解释这些变化。

Method: 定义了强度不一致性的概念，并提出了充分、必要和反事实解释的识别方法，开发了基于启发式的搜索算法来寻找解释。

Result: 证明了强度不一致性解释存在的充要条件，并提供了相应的实现工具。

Conclusion: 该方法为QBAF中的推理变化提供了形式化的解释框架，有助于理解论证强度变化的原因。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [71] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 论文提出Neural DNA (nDNA)作为AI基础模型的语义基因型表示，通过潜在几何结构捕捉模型的内在认知身份，包括谱曲率、热力学长度和信念向量场三个维度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试只衡量模型行为，但模型的本质在于其潜在几何结构。需要一种能够捕捉模型内在认知身份的方法，类似于生物DNA能够编码遗传信息。

Method: 提出nDNA表示方法，基于三个几何维度：谱曲率（揭示跨层的概念流曲率）、热力学长度（量化语义转换所需的努力）、信念向量场（描述语义扭转场）。将AI模型视为语义流体动力学系统进行分析。

Result: nDNA能够生成稳定的、坐标无关的神经网络DNA指纹，可用于追踪模型谱系、测量继承关系、检测漂移，以及研究人工认知的演化。

Conclusion: 这项工作开创了神经基因组学新领域，将AI模型视为具有可追溯内在认知的数字语义有机体，为模型比较、风险诊断和演化治理提供了新工具。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [72] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 本文提出了相似性场理论，这是一个数学框架，用于形式化实体间相似性关系及其演化的原则。该理论定义了相似性场、系统演化、概念纤维和生成算子，并形式化了一个关于智能的生成定义。


<details>
  <summary>Details</summary>
Motivation: 作者认为持久化和转换相似性关系构成了任何可理解动态系统的结构基础，需要建立一个数学框架来形式化这些原则。

Method: 定义了相似性场S: U×U→[0,1]，满足自反性；系统演化序列Z_p = (X_p, S^(p))；概念K诱导的纤维F_α(K)；以及生成算子G。

Result: 证明了两个定理：(i)不对称性阻碍相互包含；(ii)稳定性需要锚坐标或最终限制在f的水平集内。这些结果确保了相似性场演化的约束性和可解释性。

Conclusion: 相似性场理论为表征、比较和构建智能系统提供了基础语言，可用于解释大语言模型并将其作为社会认知的实验探针。

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [73] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: 提出VL-RiskFormer，一种分层堆叠的视觉-语言多模态Transformer，用于预测个体健康风险。


<details>
  <summary>Details</summary>
Motivation: 随着慢性疾病负担增加和多模态临床数据的涌现，需要统一的多模态AI框架来主动预测健康风险。

Method: 基于双流架构，采用预训练与跨模态对比、时间融合块和疾病本体图适配器四个关键创新。

Result: 在MIMIC-IV纵向队列中，平均AUROC为0.90，预期校准误差为2.7%。

Conclusion: VL-RiskFormer在多模态健康风险预测方面表现出色，具有临床应用潜力。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [74] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一个混合架构，结合了探索链、知识图谱、检索增强生成和大型语言模型，用于个性化食谱推荐，在准确性、相关性、完整性和清晰度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决个性化食谱推荐中面临的模糊用户意图处理、语义准确性保证和足够细节覆盖的挑战。

Method: 提出ChefMind混合架构：探索链(CoE)将模糊查询细化为结构化条件，知识图谱(KG)提供语义推理和可解释性，检索增强生成(RAG)补充上下文烹饪细节，大型语言模型(LLM)将输出整合为连贯推荐。

Result: 在Xiachufang数据集和手动标注查询上的评估显示，ChefMind在准确性、相关性、完整性和清晰度方面优于LLM-only、KG-only和RAG-only基线模型，平均得分8.7 vs 6.4-6.7，未处理查询降至1.6%。

Conclusion: ChefMind在个性化食谱推荐任务中表现出色，特别是在处理模糊需求方面具有鲁棒性，验证了混合架构的有效性。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [75] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 论文提出了一种"N-Plus-1"GPT代理框架，通过多个独立求解代理和比较代理来提高机械工程问题分析的可靠性，解决GPT单次求解的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: GPT在机械工程分析中存在可靠性问题，单次求解成功率仅为85%，这种不稳定性使其无法直接应用于教育或工程实践。

Method: 采用"N-Plus-1"代理框架：首先启动N个独立求解代理生成N个解决方案，然后通过比较代理汇总比较这些方案并提供推荐解。基于孔多塞陪审团定理，当单次求解成功率大于1/2且N足够大时，多数解大概率是正确的。

Result: 与商业多代理模型Grok Heavy相比，该框架在设计和性能上具有相似性，但更注重透明度和教学价值。比较代理还能整合次要解决方案中的替代问题解释或数学解法。

Conclusion: 该代理框架通过多代理协作显著提高了GPT在机械工程问题分析中的可靠性，为教育和工作应用提供了可行的解决方案。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [76] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级分层强化学习框架ComputerAgent，用于桌面应用程序控制，解决了现有多模态大语言模型在推理延迟、样本效率和设备部署方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的桌面应用控制方法存在推理延迟高、样本效率差、无法在设备上部署等问题，需要更实用的解决方案。

Method: 采用分层强化学习框架，将操作系统控制建模为两级选项过程（管理器和子策略），使用三重模态状态编码器处理视觉和上下文多样性，集成元动作和早停机制减少无效交互，使用紧凑视觉骨干网络和小型策略网络实现设备上推理。

Result: 在135个真实世界桌面任务测试中，ComputerAgent在简单任务（<8步）上达到92.1%成功率，在困难任务（≥8步）上达到58.8%成功率，模型大小减少四个数量级，推理时间减半。

Conclusion: 分层强化学习为计算机控制提供了一个实用、可扩展的替代方案，优于基于单体大语言模型的自动化方法。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [77] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 论文指出当前医疗AI基准测试存在严重问题，大型模型虽然能在基准测试中获得高分，但实际上是通过测试技巧而非真正的医学理解实现的，暴露出模型的脆弱性和捷径学习问题。


<details>
  <summary>Details</summary>
Motivation: 揭示当前医疗AI基准测试的局限性，证明高分数不能真实反映模型在现实医疗场景中的可靠性和实用性。

Method: 对六个旗舰模型在六个广泛使用的医疗基准上进行压力测试，包括移除关键输入、改变提示词等方式，并通过临床医生指导的评分标准进行评估。

Result: 发现模型在基准测试中表现出明显的脆弱性：即使移除关键输入仍能猜对答案、在微小提示变化下翻转答案、生成看似合理但有缺陷的推理。不同基准测试测量的内容差异很大但被等同对待。

Conclusion: 医疗基准测试分数不能直接反映真实世界的准备程度，需要关注模型的鲁棒性、合理推理能力以及与真实医疗需求的匹配度，而不仅仅是排行榜分数。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [78] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 该论文研究了两种计算约束策略（推理长度约束和模型量化）来降低推理模型的计算需求，并分析它们对模型安全性能的影响。


<details>
  <summary>Details</summary>
Motivation: 测试时计算扩展虽然能通过生成长链思维序列来提高推理语言模型的性能，但会显著增加计算成本。因此需要研究在计算约束下保持模型性能的方法。

Method: 采用两种方法：1）使用基于长度控制策略优化的强化学习方法微调推理模型，使其满足用户定义的推理长度；2）应用量化技术，在用户定义的计算约束下最大化链思维序列的生成。

Result: 研究发现计算约束策略可以有效降低推理模型的计算需求，但需要在计算效率与模型安全性之间进行权衡。

Conclusion: 计算约束策略是降低推理模型计算成本的有效方法，但需要仔细平衡计算效率与安全性能之间的关系。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [79] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 论文提出了Gödel测试，评估大语言模型能否为简单未解数学猜想生成正确证明，并在组合优化领域的五个猜想上测试了GPT-5的表现。


<details>
  <summary>Details</summary>
Motivation: 前沿AI模型在中学和大学数学竞赛中表现优异，但能否解决更高级数学领域的新简单猜想仍不明确，因此需要新的评估方法。

Method: 选择五个组合优化猜想，提供相关论文但不告知具体猜想，详细评估GPT-5的推理过程和证明能力。

Result: GPT-5在三个较简单问题上给出接近正确的解，甚至在一个问题上推翻了作者的猜想；在需要跨论文整合的问题上失败；在无验证猜想的难题上提出正确算法但分析失败。

Conclusion: GPT-5在常规推理上有进步，偶尔展现原创性，但在跨论文综合推理方面存在明显局限，可能是通过Gödel测试的早期步骤。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [80] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 该论文提出了首个协调关税表(HTS)代码分类的基准，基于美国海关在线搜索系统(CROSS)数据构建。作者开发了基于LLaMA-3.3-70B的Atlas模型，在10位和6位HTS代码分类上分别达到40%和57.5%的准确率，比GPT-5和Gemini模型有显著提升，且成本更低、可自托管保证数据隐私。


<details>
  <summary>Details</summary>
Motivation: HTS代码分类是全球贸易中的关键瓶颈问题，但机器学习社区对此关注不足。错误分类可能导致货物运输完全停滞，主要邮政运营商曾因海关文件不完整而暂停对美投递。

Method: 基于美国海关CROSS系统构建首个HTS代码分类基准数据集，对领先的LLMs进行评估，并微调LLaMA-3.3-70B模型得到Atlas模型。

Result: Atlas模型在10位HTS代码分类上达到40%准确率，6位分类达到57.5%准确率，比GPT-5-Thinking和Gemini-2.5-Pro-Thinking分别提升15和27.5个百分点。同时成本降低5-8倍，且支持自托管。

Conclusion: 虽然Atlas模型建立了强基线，但HTS分类任务仍极具挑战性。通过发布数据集和模型，旨在将HTS分类定位为新的社区基准任务，推动检索、推理和对齐方面的未来研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [81] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC是一个新的函数调用基准测试，专注于评估LLM对参数描述中格式指令的遵循能力，填补了现有基准测试的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试如BFCL、tau^2-Bench和ACEBench只评估参数正确性，但不测试对格式指令（如双引号、ISO日期格式）的遵循能力，这在现实AI代理系统中很重要。

Method: IFEval-FC在JSON schema描述中直接编码可验证的格式要求，包含750个测试用例，每个用例包含一个函数和对应的用户查询，评估完全基于算法。

Result: 结果显示即使是GPT-5和Claude 4.1 Opus等最先进的专有模型也经常无法遵循基本格式规则，揭示了现实世界代理系统的实际限制。

Conclusion: IFEval-FC强调了对格式指令遵循能力评估的重要性，代码和数据已公开，为函数调用能力评估提供了新的维度。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [82] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: Memory-QA是一个新颖的视觉记忆问答任务，Pensieve管道通过记忆增强、时空感知检索和多记忆问答微调，在QA准确率上比现有方法提升高达14%


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中基于视觉记忆的回忆问答任务，应对任务导向记忆创建、时空信息利用以及多记忆融合等独特挑战

Method: 提出Pensieve综合管道，包含记忆特定增强、时空感知多信号检索和多记忆问答微调三个核心模块

Result: 在构建的多模态基准测试中，Pensieve相比最先进方法在QA准确率上提升高达14%

Conclusion: Memory-QA任务具有重要现实意义，Pensieve管道有效解决了该任务的核心挑战，为视觉记忆问答领域提供了新的解决方案

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [83] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个用于击剑裁判的AI助手原型，通过姿态识别和规则推理来解决击剑裁判中的主观判断、人为错误等问题


<details>
  <summary>Details</summary>
Motivation: 击剑运动面临裁判主观判断、人为错误、偏见以及训练环境中裁判资源有限等挑战，需要自动化裁判辅助系统

Method: 结合姿态多标签动作识别和规则推理：从视频提取2D关节位置，归一化后计算101维运动学特征，使用Transformer进行多标签动作和剑尖分类，再应用语言模型编码优先权规则进行决策

Result: 在有限标注数据下，5折交叉验证平均macro-F1得分为0.549，优于TCN、BiLSTM和普通Transformer等基线模型

Conclusion: 虽然尚未达到部署水平，但结果展示了在击剑裁判自动化辅助方面的有前景路径，并为AI在击剑教练等领域的应用开辟了新机会

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [84] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: LLMZ+是一种基于提示白名单的防御机制，通过只允许上下文适当的消息与代理LLM交互，提供对越狱攻击的强大弹性。


<details>
  <summary>Details</summary>
Motivation: 代理AI相比传统模型具有更高的安全风险，因为它们拥有对数据源和API工具的特权访问，且依赖AI的非确定性行为。现有防御机制主要依赖恶意意图检测，但这种方法存在局限性。

Method: 提出LLMZ+方法，采用提示白名单机制，只允许符合预定义用例和操作边界的消息与代理LLM进行交互，利用上下文特异性来保证安全性。

Result: 实证评估显示LLMZ+对常见越狱提示具有强大弹性，同时不干扰合法的业务通信。在实验设置中，误报率和漏报率均可降至0。

Conclusion: LLMZ+方法简化了安全框架，增强了长期弹性，减少了维持LLM信息安全所需的资源，是一种超越传统检测方法的替代方案。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [85] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 提出一种新方法，通过分解问题生成方程并使用外部符号求解器，结合答案估计验证机制，在数学应用题求解上达到新的最先进水平


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决数学应用题时面临挑战，需要改进推理和数学能力

Method: 先提示LLM从问题分解创建方程，用外部符号求解器生成答案，然后让LLM估计答案进行验证，失败时采用迭代修正过程

Result: 在数值和代数数学应用题数据集上比之前最佳结果平均提升近2%，在三角函数应用题上也取得满意结果

Conclusion: 该方法有效提升了LLM解决数学应用题的能力，并引入了两个新数据集推进LLM推理能力测试

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [86] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 提出了一种结合地理空间建模与进化学习的新型基于代理的气候风险评估框架，用于量化直接和级联气候风险


<details>
  <summary>Details</summary>
Motivation: 气候风险评估需要建模空间异质性灾害与适应性经济系统之间的复杂相互作用

Method: 结合Mesa空间建模与CLIMADA气候影响评估，引入自适应学习行为，让企业通过基于适应度的选择和变异来演化预算分配、定价、工资和风险适应策略

Result: 使用RCP8.5情景下的河流洪水预测到2100年，显示进化适应使企业能够在数十年气候压力后恢复到基线生产水平；未直接暴露于洪水的代理人也面临供应链中断影响，世纪末商品平均价格比基线高5.6%

Conclusion: 该开源框架为金融机构和公司提供了量化直接和级联气候风险的工具，同时评估成本效益高的适应策略

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [87] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个低成本图检索增强生成框架，通过个性化PageRank在检索阶段实现高效图构建，仅需3%-11%的token消耗即可达到主流图RAG方法80%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有图RAG系统在构建图时LLM token使用成本过高，阻碍了大规模应用，需要开发更经济的解决方案。

Method: 受HippoRAG启发，在检索阶段引入个性化PageRank(PPR)算法，优化图构建过程以显著降低token消耗。

Result: TERAG在保持准确性的同时，将输出token消耗降低至传统方法的3%-11%，达到至少80%的准确率。

Conclusion: TERAG证明了通过优化检索算法可以大幅降低图RAG系统的token成本，为大规模应用提供了可行方案。

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [88] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: 该论文旨在澄清机器学习模型与其明确描述之间的差异，并完善语义保持的概念，以确保模型准确复制，应用于工业用例。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在航空系统中的潜在应用增加，确保其安全运行并符合相关指导标准（如EASA概念文件和ED-324）变得至关重要。论文旨在解决如何验证ML模型在目标环境中保持其预期功能和训练性能的问题。

Method: 论文通过定义机器学习模型描述（MLMD）来区分模型本身与其明确描述，并细化语义保持的概念。随后，将这一方法应用于多个工业用例，构建和比较不同的目标模型。

Result: 通过应用MLMD和语义保持的概念，论文展示了如何确保ML模型在目标环境中准确复制其训练性能，从而满足航空安全标准的要求。

Conclusion: 论文提出的MLMD和语义保持框架为ML模型在安全关键系统中的合规性提供了理论基础和实践方法，有助于推动ML在航空等领域的可靠应用。

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [89] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文系统综述了大型语言模型在医学领域的最新研究进展，包括训练技术、医疗应用、优势与局限，并对医学LLMs进行分类和评估方法分类，提出解决现有挑战的方案和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，大型语言模型在医学领域展现出巨大应用潜力，需要系统梳理当前研究进展，为后续研究提供指导。

Method: 采用系统性文献综述方法，深入分析医学大型模型的训练技术、医疗场景适应性和相关应用，创新性地将医学LLMs分为三种类型，评估方法分为两类。

Result: 总结了医学LLMs的发展现状，识别了现有挑战，并提出了相应的解决方案。

Conclusion: 通过系统综述，强调了开发医学LLMs的必要性，深化了对当前发展状态的理解，为后续研究提供了清晰指导。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [90] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出自主数据代理（DataAgents）的概念，通过集成LLM推理与任务分解、行动推理和工具调用，实现从复杂非结构化数据到可操作知识的自动化转换。


<details>
  <summary>Details</summary>
Motivation: 随着数据规模和复杂性的增长，数据准备、转换和分析工作仍然劳动密集且难以扩展。数据与AI之间的对齐至关重要，但现有数据往往没有为AI使用进行优化。

Method: DataAgents通过动态规划工作流、调用强大工具和适应多样化数据任务，能够处理数据收集、集成、预处理、选择、转换、重加权、增强、重编程、修复和检索等操作。

Result: DataAgents代表了向自主数据到知识系统的范式转变，能够将复杂非结构化数据转化为连贯可操作的知识。

Conclusion: 需要协同努力推进行动工作流优化、建立开放数据集和基准生态系统、保护隐私、平衡效率与可扩展性，并开发可信赖的DataAgent防护机制以防止恶意行为。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [91] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 提出了经验缩放框架，通过自主环境交互和协作经验共享实现LLM的持续进化，突破静态人类生成数据的限制


<details>
  <summary>Details</summary>
Motivation: 传统通过扩大模型规模、训练数据和计算能力的方法已接近饱和，人类生成文本资源耗尽，需要新的持续学习机制

Method: 经验缩放框架包括捕获原始交互、提炼为紧凑可重用知识、定期优化存储内容以保持相关性和效率

Result: 在模拟真实场景中验证，包括泛化到未见相关任务、重复查询和知识库过饱和情况，经验缩放提高了准确性，维持了长期性能

Conclusion: 结构化部署后学习能够扩展LLM能力，超越静态人类生成数据的限制，为持续智能进步提供可扩展路径

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [92] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: ADS是一个分布式目录服务，用于发现AI代理的能力、元数据和来源，采用内容寻址存储、分层分类和加密签名，支持高效、可验证的多维发现。


<details>
  <summary>Details</summary>
Motivation: 解决异构多代理系统中代理能力发现的问题，提供可验证的元数据和来源信息，支持新兴代理模式的扩展性。

Method: 基于Open Agentic Schema Framework构建，采用两级映射的Kademlia分布式哈希表，重用OCI/ORAS基础设施进行工件分发，集成Sigstore进行来源验证。

Result: 实现了高效的代理能力发现系统，支持多维查询和可验证的元数据，具备良好的安全性和性能特性。

Conclusion: ADS为新兴代理注册和互操作性倡议提供了重要的基础设施，能够有效支持异构多代理系统的能力发现和管理。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [93] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: LLMCHECKER是一种基于模型检查的验证方法，用于验证LLM文本生成过程的概率计算树逻辑(PCTL)属性。该方法通过α-k有界文本生成来限制生成过程中的token选择，从而实现对LLM文本生成一致性的形式化验证。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对LLM文本生成过程一致性的形式化验证方法。作者观察到在文本生成过程中通常只有有限数量的token被选择，且这些选择并不总是相同，这促使开发一种能够验证PCTL属性的系统化方法。

Method: 提出α-k有界文本生成方法：在每个生成步骤中，只考虑top-k个token中累积概率超过阈值α的token。LLMCHECKER结合初始字符串和后续的top-k token，支持多种文本量化方法（如文本质量和偏见评估），然后对α-k有界LLM进行PCTL属性验证。

Result: 该方法在多个LLM（包括Llama、Gemma、Mistral、Genstruct和BERT）上进行了验证，证明了其适用性。这是首次将基于PCTL的模型检查应用于LLM文本生成过程的一致性验证。

Conclusion: LLMCHECKER提供了一种有效的形式化验证框架，能够确保LLM文本生成过程满足特定的PCTL属性要求，为LLM的可信性和可靠性提供了新的验证手段。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [94] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 提出了一个模块化框架用于ICD-10-CM编码预测，通过原则性模型选择、冗余感知数据采样和结构化输入设计来解决LLM在医疗编码中的挑战。


<details>
  <summary>Details</summary>
Motivation: ICD编码对于临床文档、计费和医疗分析至关重要，但目前仍是劳动密集型且易出错的任务。尽管LLM在自动化ICD编码方面有潜力，但在基础模型选择、输入上下文化和训练数据冗余方面存在挑战。

Method: 采用模块化框架，包括LLM-as-judge评估协议与Plackett-Luce聚合来评估开源LLM，引入嵌入相似性度量和冗余感知采样策略，利用台湾医院的结构化出院摘要评估上下文效果。

Result: 在两个机构数据集上的实验表明，经过微调的基础模型在内部和外部评估中始终优于基线LLM。包含更多临床部分持续提高预测性能。

Conclusion: 该研究使用开源LLM建立了实用且原则性的ICD-10-CM编码预测方法，为自动化医疗编码系统的实际部署提供了可扩展的机构就绪解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [95] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了一种名为MAPO（Mixed Advantage Policy Optimization）的GRPO策略，解决了现有方法中的优势函数反转和镜像问题，通过动态重新加权优势函数来适应不同轨迹确定性的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在优势函数分配上存在优势反转和优势镜像问题，阻碍了不同查询样本间合理的优势分配。

Method: 提出MAPO策略，引入优势百分比偏差来处理高确定性轨迹样本，并动态重新加权优势函数以适应不同轨迹确定性的样本。

Result: 与相关最先进方法的比较以及不同优势变体的消融研究验证了该方法的有效性。

Conclusion: MAPO是一种简单但有效的GRPO策略，能够更好地处理不同确定性轨迹样本的优势函数配置问题。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [96] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 提出了ProfileBench基准和Conf-Profile框架，通过置信度驱动的两阶段方法解决用户画像中的标签稀缺和噪声问题


<details>
  <summary>Details</summary>
Motivation: 用户画像缺乏全面基准，且面临标签收集困难、用户信息异构噪声等挑战，影响LLMs的可靠性

Method: 两阶段框架：1）利用高级LLMs合成高质量标签，置信度加权投票和校准；2）置信度引导的无监督强化学习，进行难度过滤和奖励加权

Result: 在Qwen3-8B上F1分数提升13.97，显著改善用户画像性能

Conclusion: Conf-Profile框架通过置信度驱动的方法有效解决了用户画像中的标签稀缺和可靠性问题

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [97] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: 本文提出了一个统一的LLM记忆定义和四部分分类法（参数化、上下文、外部、程序/情景记忆），建立了记忆四元组框架，并开发了分层评估协议来标准化LLM记忆研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM记忆研究中的定义不一致、评估方法异构和缺乏可比性问题，需要建立统一的框架来协调机制、评估和治理。

Method: 采用三设置协议（仅参数、离线检索、在线检索）解耦能力与信息可用性，构建分层评估框架，并提出了DMM Gov治理系统来协调各种更新和遗忘技术。

Result: 建立了一个可重现、可比较和可治理的坐标系，包含参数记忆评估、上下文记忆分析、外部记忆验证以及程序/情景记忆测试。

Conclusion: 该框架为LLM记忆研究提供了标准化基础，提出了四个可测试命题，支持记忆机制、评估和治理的集成研究。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [98] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个5600亿参数的开放源码MoE推理模型，通过精心设计的训练流程（包括长链思维数据冷启动和大规模强化学习）实现高效推理能力，在复杂推理任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的开放源码推理模型，通过创新的训练策略提升模型在正式推理和代理推理方面的专业能力，促进推理系统和代理AI研究的进步。

Method: 采用长链思维数据冷启动训练策略，然后使用领域并行训练方案将不同领域的专家模型融合为单一模型，整个过程由DORA系统（大规模RL框架）支持，实现3倍以上的训练加速。

Result: 在复杂推理任务上达到开放源码模型的最先进性能，在AIME-25上代理推理效率显著提升，平均token消耗减少64.5%（从19,653降至6,965），且任务准确率不降低。

Conclusion: LongCat-Flash-Thinking展示了高效的推理能力，特别是在代理推理方面的显著效率提升，为推理系统和代理AI研究提供了有价值的开放源码模型。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [99] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 本文系统研究了视觉语言模型中的视觉空间推理能力，提出了空间智能的三层次分类，并创建了包含20个开源数据集的空间智能基准SIBench。实验发现当前模型在感知任务上表现良好，但在理解和规划任务上存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理是人类核心认知能力，对推进具身智能和自主系统至关重要。尽管视觉语言模型取得进展，但实现人类水平的视觉空间推理仍极具挑战，需要系统研究当前方法的能力和局限。

Method: 通过回顾现有方法（输入模态、模型架构、训练策略、推理机制），将空间智能分为基础感知、空间理解、空间规划三个层次，并构建SIBench基准包含23个任务设置。

Result: 实验表明最先进的视觉语言模型在感知任务上有竞争力，但在理解和规划任务上表现不佳，特别是在数值估计、多视图推理、时间动态和空间想象方面存在明显差距。

Conclusion: 研究揭示了实现空间智能面临的重大挑战，同时提供了系统路线图和全面基准来推动该领域未来研究。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [100] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 本文提出了DEAL框架，结合LoRA和持续微调策略，通过知识保留和自适应参数更新模块解决传统微调方法的灾难性遗忘和数据效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法存在灾难性遗忘和次优数据效率的问题，限制了LLMs在实际应用中的适用性。

Method: DEAL框架整合了低秩适应（LoRA）和持续微调策略，包含知识保留和自适应参数更新模块。

Result: 在15个不同数据集上的实验表明，DEAL在任务准确性和资源效率方面显著优于基线方法。

Conclusion: 该方法通过提升任务性能同时改善资源效率，展示了在LLMs中推进持续适应的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [101] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 本文首次对基于大语言模型（LLM）的智能体中的幻觉问题进行了全面调查，提出了新的分类法识别不同阶段出现的幻觉类型，深入分析了18种触发原因，并总结了幻觉缓解和检测方法。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM-based agents在多个领域展现出强大潜力，但幻觉问题严重影响了系统的可靠性和任务执行准确性，需要系统性地理解和应对这一挑战。

Method: 通过分析智能体的完整工作流程，提出新的幻觉分类法；深入分析18种幻觉触发原因；系统总结现有研究中的幻觉缓解和检测方法。

Result: 建立了首个全面的LLM-based agents幻觉调查框架，为理解和解决幻觉问题提供了系统性的理论基础和方法指导。

Conclusion: 该调查为开发更鲁棒可靠的智能体系统指明了方向，有望推动该领域的进一步发展。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [102] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: 研究大型语言模型能否从数学可解释的推荐模型中生成有效的用户导向解释，通过用户研究评估不同解释策略的质量。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI研究多依赖自动评估指标，但无法真实反映用户需求和感知，需要采用用户中心的方法来评估解释质量。

Method: 基于约束矩阵分解的推荐模型，利用精心设计的LLM提示将模型结构转换为自然语言解释，通过326名参与者的用户研究评估五种关键维度。

Result: 所有解释类型都获得良好接受，不同策略间存在适度统计差异，用户评论提供了超出定量结果的补充见解。

Conclusion: LLM能够从可解释推荐模型生成有效的用户导向解释，用户中心评估方法为解释质量提供了更全面的理解。

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [103] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在物流公司出库仓库流程中的表现，发现深度学习模型准确率最高，但浅层方法如传统提升技术在计算资源需求上更具优势。


<details>
  <summary>Details</summary>
Motivation: 预测性过程监控旨在预测正在执行的过程的未来状态，其中剩余时间预测是常见目标。本文旨在在真实物流场景中比较不同方法的性能。

Method: 在物流公司航空业务的出库仓库过程中，使用包含169,523条轨迹的事件日志，比较了四种剩余时间预测方法，包括深度学习模型和浅层方法如传统提升技术。

Result: 深度学习模型达到最高准确率，但浅层方法如传统提升技术在准确率上具有竞争力，且需要显著更少的计算资源。

Conclusion: 虽然深度学习在准确率上表现最佳，但浅层方法在计算效率和实用性方面具有优势，特别是在资源受限的环境中。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [104] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 该论文提出了基于玩家视角的Landmarks、Monuments和Beacons概念，用于自动分解和评估程序生成内容的子组件，旨在改善算法评估与人类体验的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前算法评估程序生成内容时难以找到与人类体验一致的指标，特别是对于复合产物。需要满足多种属性的概念来实现自动分解。

Method: 借鉴游戏研究和游戏AI研究，引入基于可感知性、唤起性和行动召唤的Landmarks、Monuments和Beacons概念，这些概念具有通用性，可通过现有技术进行识别和评估。

Result: 提出的概念框架为程序生成内容的自动分解和子组件评估开辟了路径，适用于混合主动PCG和组合PCG等领域。

Conclusion: 该方法旨在连接人文学科和技术游戏研究，实现更好的计算PCG评估，虽然重点在混合主动PCG，但具有更广泛的应用潜力。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [105] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本文提出了一个使用可观测源作为辅助变量的因果表示学习框架，能够在已知潜在因果图的情况下识别整个潜在变量，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有因果表示学习方法通常需要已知辅助变量来实现可识别性，但这些方法将辅助变量限制在混合函数外部。然而在某些情况下，系统驱动的潜在因素可以从数据中轻松观测或提取，可能有助于识别。

Method: 引入可观测源作为辅助变量的框架，使用保体积编码器实现潜在变量的子空间变换和置换识别，并提供变量选择方案来选择最大化潜在因素可恢复性的辅助变量。

Result: 实验证明该框架在合成图和图像数据上有效，能够识别整个潜在变量，扩展了现有方法的边界。

Conclusion: 通过将可观测源作为辅助变量，本文框架能够更有效地识别潜在因素，为因果表示学习提供了新的思路和方法。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [106] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC提出了一种基于代码驱动规划和领域自适应批评器的LLM规划方法，通过生成多样化高级规划程序并利用训练好的批评器评估候选计划，在减少查询成本的同时提升长期奖励对齐。


<details>
  <summary>Details</summary>
Motivation: 现有LLM规划方法依赖频繁查询进行迭代优化，存在查询成本高且仅关注短期反馈的问题，无法有效对齐长期奖励。

Method: CoPiC使用LLM生成多样化高级规划程序，通过领域自适应批评器评估候选计划，选择最符合长期奖励的方案执行。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building三个环境中，CoPiC相比AdaPlanner和Reflexion基线，平均成功率提升23.33%，查询成本降低91.27%。

Conclusion: CoPiC通过代码驱动规划和领域自适应批评器的结合，有效解决了LLM规划中的查询成本高和长期奖励对齐问题，在多个复杂环境中表现出优越性能。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [107] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种多智能体系统初始化方法，通过优化智能体团队结构来提升系统性能，结合自然语言格式化机制和帕累托平衡选择策略。


<details>
  <summary>Details</summary>
Motivation: 现有MAS初始化方法未能充分考虑智能体在后续阶段的协作需求，需要更好的团队组成优化方法。

Method: AgentInit包含多轮智能体交互反思、自然语言格式化机制确保一致性，以及基于帕累托原则的平衡团队选择策略，同时考虑团队多样性和任务相关性。

Result: 实验显示AgentInit在各种框架和任务中均优于现有初始化方法和预定义策略，性能提升分别达1.2和1.6倍，同时显著减少token消耗。

Conclusion: AgentInit具有良好的可迁移性和适应性，其关键组件有效性得到验证，可作为可靠的MAS初始化方法。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [108] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在阿拉伯世界的跨文化常识推理迁移，发现仅需12个特定文化示例就能平均提升10%的性能，且来自印尼和美国的跨文化演示也能实现类似效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在西方中心偏见，限制了其在多元文化背景下的有效性。虽然已有研究探索文化对齐，但跨文化迁移潜力（利用一种文化的对齐来提升其他文化性能）仍未被充分探索。

Method: 使用涵盖13个阿拉伯国家的文化基础常识推理数据集，评估轻量级对齐方法（上下文学习、演示强化DITTO）以及监督微调和直接偏好优化等基线方法。

Result: 仅需12个特定文化示例就能平均提升10%的性能；来自印尼和美国的跨文化演示在多项选择推理中能达到或超越文化内对齐效果。

Conclusion: 高效的跨文化对齐是可行的，这为将LLMs适配到低资源文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>
